{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d03a17",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cd5dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/atmatech/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "# Load informal-to-formal dictionary\n",
    "with open(\"/home/atmatech/task/sentiment-nawatech/informal_to_formal.json\") as json_file:\n",
    "    dictionaries = json.load(json_file)\n",
    "\n",
    "# Load Sastrawi stopwords and customize\n",
    "factory = StopWordRemoverFactory()\n",
    "stopwords = factory.get_stop_words()\n",
    "important_words = {'bisa', 'tidak', 'lebih', 'baik', 'buruk', 'suka', 'benci', 'cinta', 'senang', 'marah', 'kesal', 'bagus', 'jelek'}\n",
    "stopwords = [word for word in stopwords if word not in important_words]\n",
    "\n",
    "# Inisialisasi stemmer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "stemmer_factory = StemmerFactory()\n",
    "stemmer = stemmer_factory.create_stemmer()\n",
    "\n",
    "def cleansing(text):\n",
    "    # 1. Hapus special tokens\n",
    "    def strip_special_tokens(text):\n",
    "        return re.sub(r'<[^<>]+>', '', text)\n",
    "    \n",
    "    # 2. Hapus simbol (#) tetap mempertahankan kata setelahnya\n",
    "    def strip_hashtags(text):\n",
    "        return re.sub(r\"#(\\w+)\", r\"\\1\", text)\n",
    "    \n",
    "    # 3.a  Hapus tautan (link)\n",
    "    def strip_links(text):\n",
    "        return re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # 3.b Hapus mention (@username)\n",
    "    def strip_mention(text):\n",
    "        return re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
    "    \n",
    "    # 3.c Hapus tag RT (retweet)\n",
    "    def strip_retweet(text):\n",
    "        return re.sub(r'\\bRT\\b[\\s]*', '', text)\n",
    "    \n",
    "    # 3.d Hapus tanda baca (punctuation)\n",
    "    def strip_punctuation(text):\n",
    "        return re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # 3.e Mengubah karakter newline menadi spasi.\n",
    "    def strip_newline(text):\n",
    "        return text.replace('\\n', ' ')\n",
    "\n",
    "    # 4. Mengubah karakter kata menjadi huruf kecil (lowercase)\n",
    "    def case_folding(text):\n",
    "        return text.lower()\n",
    "    \n",
    "    # 5. Mengubah teks menjadi list token\n",
    "    def tokenizer(text):\n",
    "        return nltk.word_tokenize(text)\n",
    "    \n",
    "    # 6. Normalisasi kata informal/slang ke formal berdasarkan kamus slang (dictionaries)\n",
    "    def informal_to_formal(tokens):\n",
    "        return [dictionaries.get(word, word).lower() for word in tokens]\n",
    "\n",
    "    # 7. Hapus stopwords dengan penyesuaian kustomisasi daftar stopwords\n",
    "    def remove_stopwords(tokens):\n",
    "        return [word for word in tokens if word not in stopwords and word != '']\n",
    "    \n",
    "    # 8. Menggabungkan kembali list token menjadi teks utuh\n",
    "    def detokenizer(tokens):\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    # 9. Stemming untuk mengubah kata ke bentuk dasarnya\n",
    "    def stemming(text):\n",
    "        return stemmer.stem(text)\n",
    "    \n",
    "    # Cleaning (Text Level)\n",
    "    text = strip_special_tokens(text)\n",
    "    text = strip_hashtags(text)\n",
    "    text = strip_links(text)\n",
    "    text = strip_mention(text)\n",
    "    text = strip_retweet(text)\n",
    "    text = strip_punctuation(text)\n",
    "    text = strip_newline(text)\n",
    "    text = case_folding(text)\n",
    "    \n",
    "    # Tokenisasi\n",
    "    tokens = tokenizer(text)\n",
    "\n",
    "    # Transformasi (Token Level)\n",
    "    tokens = informal_to_formal(tokens)   \n",
    "    tokens = remove_stopwords(tokens) \n",
    "    \n",
    "    # Detokenisasi\n",
    "    text = detokenizer(tokens)\n",
    "\n",
    "    # Transformasi (Text Level)\n",
    "    text = stemmer.stem(text)\n",
    "\n",
    "    return text.strip() # Hapus spasi ekstra pada awal dan akhir teks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b5429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teks setelah cleansing: lebih baik\n",
      "Prediksi Sentimen: positive\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load model & vectorizer\n",
    "svm_model = joblib.load(\"svm-sentiment-model.joblib\")\n",
    "tfidf = joblib.load(\"TF-IDF.joblib\")\n",
    "\n",
    "# Input teks\n",
    "text_baru = \"Lebih baik <PROVIDER_NAME>\"\n",
    "\n",
    "# Preprocessing\n",
    "text_baru_clean = cleansing(text_baru)\n",
    "print(\"Teks setelah cleansing:\", text_baru_clean)\n",
    "\n",
    "# Transform ke TF-IDF\n",
    "text_baru_vec = tfidf.transform([text_baru_clean])\n",
    "\n",
    "# Ubah ke dense array karena model dilatih dengan .toarray()\n",
    "text_baru_dense = text_baru_vec.toarray()\n",
    "\n",
    "# Prediksi\n",
    "prediksi = svm_model.predict(text_baru_dense)[0]\n",
    "\n",
    "# Interpretasi hasil\n",
    "hasil = \"positive\" if prediksi == 1 else \"negative\"\n",
    "print(\"Prediksi Sentimen:\", hasil)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment-nawatech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
